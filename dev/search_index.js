var documenterSearchIndex = {"docs":
[{"location":"","page":"Home","title":"Home","text":"CurrentModule = DifferentiableKernelFunctions","category":"page"},{"location":"#DifferentiableKernelFunctions","page":"Home","title":"DifferentiableKernelFunctions","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for DifferentiableKernelFunctions.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [DifferentiableKernelFunctions]","category":"page"},{"location":"#DifferentiableKernelFunctions.EnableDiff","page":"Home","title":"DifferentiableKernelFunctions.EnableDiff","text":"EnableDiff\n\nA thin wrapper around Kernels enabling the machinery which allows you to input (x, ∂ᵢ), (y, ∂ⱼ) where ∂ᵢ, ∂ⱼ are of Partial type (see partial) in order to calculate k((x ᵢ) (yⱼ)) = textCov(partial_i Z(x) partial_j Z(y)) for Z with k(xy) = textCov(Z(x) Z(y)).\n\n!!! warning Only apply this wrapper at the very end. Kerneltransformations should be applied beforehand.\n\n!!! info While this machinery could in principle be enabled for all Kernel by default, the covariance of derivatives of an isotropic kernel are no longer isotropic. This forces the use of less specialized methods. So for now you have to opt-in with this Wrapper.\n\nExample:\n\njulia> k = EnableDiff(SEKernel());\n\njulia> k((0, partial(1)), 0) # calculate Cov(∂₁Z(0), Z(0))\n0.0\n\njulia> k(0,0) # normal input still works\n1.0\n\n\n\n\n\n","category":"type"},{"location":"#DifferentiableKernelFunctions.apply_partial-Union{Tuple{T}, Tuple{Any, Tuple{Vararg{T}}, Tuple{Vararg{T}}}} where T<:Union{Int64, Base.AbstractCartesianIndex}","page":"Home","title":"DifferentiableKernelFunctions.apply_partial","text":"Take the partial derivative of a function with two dim-dimensional inputs, i.e. 2*dim dimensional input\n\n\n\n\n\n","category":"method"},{"location":"#DifferentiableKernelFunctions.diffKernelCall-Union{Tuple{T}, Tuple{T, Tuple{Any, DifferentiableKernelFunctions.Partial}, Tuple{Any, DifferentiableKernelFunctions.Partial}}} where T<:Kernel","page":"Home","title":"DifferentiableKernelFunctions.diffKernelCall","text":"diffKernelCall(k::T, (x,px)::DiffPt, (y,py)::DiffPt) where {Dim, T<:Kernel}\n\nspecialization for DiffPt. Unboxes the partial instructions from DiffPt and applies them to k, evaluates them at the positions of DiffPt\n\n\n\n\n\n","category":"method"},{"location":"#DifferentiableKernelFunctions.lazy_flatten-Tuple","page":"Home","title":"DifferentiableKernelFunctions.lazy_flatten","text":"lazy_flatten(vectors...)\n\nThe output is a lazy form of\n\ncollect(Iterators.flatten(vectors...))\n\ni.e. it is an AbstractArray in contrast to Iterators.flatten(vectors...). So is accessible with getindex and gets default Array implementations for free. In particular it can be passed to Base.PermutedDimsArrayfor lazy permutation andvec()to obtain a lazyBase.ReshapedArray`.\n\n\n\n\n\n","category":"method"},{"location":"#DifferentiableKernelFunctions.tangentCurve-Tuple{AbstractArray, Union{Int64, Base.AbstractCartesianIndex}}","page":"Home","title":"DifferentiableKernelFunctions.tangentCurve","text":"tangentCurve(x₀, i::IndexType)\n\nreturns the function (t ↦ x₀ + teᵢ) where eᵢ is the unit vector at index i\n\n\n\n\n\n","category":"method"}]
}
